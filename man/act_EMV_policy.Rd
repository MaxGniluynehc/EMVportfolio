% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/act_EMV_policy.R
\name{act_EMV_policy}
\alias{act_EMV_policy}
\alias{V_function}
\alias{TD}
\alias{TD_error}
\title{The `act_EMV_policy` Function}
\usage{
act_EMV_policy(
  t,
  x,
  w = 1.4,
  phi1 = 1,
  phi2 = 0.5,
  lambda = 2,
  invest_hrzn = 1
)

V_function(
  t,
  x,
  w = 1,
  theta0 = 1,
  theta1 = 1,
  theta2 = 1,
  theta3 = 1,
  invest_hrzn = 1
)

TD(
  t_is,
  x_is,
  dt = 1/252,
  w = 1.4,
  theta0 = 1,
  theta1 = 1,
  theta2 = 1,
  theta3 = 1,
  phi1 = 1,
  phi2 = 0.5,
  lambda = 2,
  invest_hrzn = 1
)

TD_error(
  t_is,
  x_is,
  dt = 1/252,
  w = 1,
  theta0 = 1,
  theta1 = 1,
  theta2 = 1,
  theta3 = 1,
  phi1 = 1,
  phi2 = 0.5
)
}
\arguments{
\item{t}{(Required, numeric) current time}

\item{x}{(Required, numeric) current wealth}

\item{w}{(Optional, numeric) Lagrange multiplier, default to 1.4}

\item{phi1}{(Optional, numeric) a parameter in the optimal EMV policy distribution, default to 1}

\item{phi2}{(Optional, numeric) a parameter in the optimal EMV policy distribution, default to 0.5}

\item{lambda}{(Optional, numeric) the exploratory weight, default to 2}

\item{invest_hrzn}{(Optional, numeric) investment horizon, total length of the investment
period in years, default to 1.}

\item{theta0}{(Optional, numeric) a parameter of the optimal value function, default to 1}

\item{theta1}{(Optional, numeric) a parameter of the optimal value function, default to 1}

\item{theta2}{(Optional, numeric) a parameter of the optimal value function, default to 1}

\item{theta3}{(Optional, numeric) a parameter of the optimal value function, default to 1}

\item{t_is}{a vector of time steps}

\item{x_is}{a vector of wealth over time}

\item{dt}{(Optional, numeric) the discretization of continuous time, default to 1/252,}
}
\value{
The amount of money invest in stock (a numerical value of length 1).
}
\description{
`act_EMV_policy()` make an investment decision following the Exploratory Mean-Variance (EMV) policy.
Suppose the current wealth at time t is \eqn{x_t}, then the optimal EMV policy is a Gaussian
distribution parameterized by \eqn{\phi = (\phi_1, \phi_2)}, i.e., \eqn{\pi^\phi(u; t,x,\omega)
= N \left(\sqrt{\frac{2\phi_2}{\lambda \pi}} e^{\phi_1 - \frac{1}{2}} (x-\omega),
\frac{1}{2\pi} e^{2\phi_2(T-t) + 2\phi_1 - 1} \right)}.
Then the optimal investment in the stock \eqn{u_t^*} is sampled from the Gaussian policy
distribution and the rest \eqn{x_t - u_t} is invested
in the bond.

`V_function` computes the optimal value function in the EMV problem, parameterized by
\eqn{\theta = (\theta_0, \theta_1, \theta_2, \theta_3)}. Mathematically, this is
\eqn{V^\theta(t,x) = (x-\omega)^2 e^{-\theta_3 (T-t)} + \theta_2 t^2 + \theta_1 t + \theta_0}.

`TD` computes temporal difference as \eqn{TD(t,x) = \frac{V^\theta(t+1, X_{t+1}) - V^\theta(t, X_{t})}{\Delta t} - \lambda(\phi_1 + \phi_2(T-t))}.

`TD_error` computes temporal difference error as \eqn{C(\theta, \phi) = \frac{1}{2} \sum_{t,x} TD(t,x)^2 \cdot dt}.
}
\examples{
# Take an exploratory action following the EMV policy
act_EMV_policy(t = 1/252, x=1)

# Compute the value function
V_function(t = 1/252, x=1)

# Compute temporal differences
TD(t_is = c(1/252, 2/252, 3/252), x_is = c(1, 1.2, 0.8))

# Compute the temporal difference error
TD_error(t_is = c(1/252, 2/252, 3/252), x_is = c(1, 1.2, 0.8))

}
